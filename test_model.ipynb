{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.utils_data import load_PeMS04_flow_data, preprocess_PeMS_data, createLoaders, TimeSeriesDataset\n",
    "from src.utils_graph import compute_laplacian_with_self_loop\n",
    "from src.models import TGCN, GRUModel, LSTMModel, train_model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PeMS, df_distance  = load_PeMS04_flow_data()\n",
    "n_neighbors = 15\n",
    "normalization = \"divide_by_max\"\n",
    "df_PeMS, adjacency_matrix_PeMS, maximum = preprocess_PeMS_data(df_PeMS, df_distance, init_node=0, n_neighbors=n_neighbors, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sliding window size and stride\n",
    "_window_size = 7\n",
    "_stride = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_TGCN, val_loader_TGCN, test_loader_TGCN = createLoaders(df_PeMS, window_size=_window_size, stride=_stride)\n",
    "model_TGCN = TGCN(adjacency_matrix_PeMS, hidden_dim=32, output_size=len(df_PeMS.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs_TGCN = 100\n",
    "model_path = f\"./{normalization}/epoch_{num_epochs_TGCN}/nb_captor_{n_neighbors+1}/TGCN_model.pkl\"\n",
    "_ , valid_losses = train_model(model_TGCN, train_loader_TGCN, val_loader_TGCN, model_path=model_path, num_epochs=num_epochs_TGCN, remove=False)\n",
    "plt.plot(valid_losses, label=\"valid_losses\")\n",
    "plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_univaritate_LSTM = {}\n",
    "\n",
    "for i in range(n_neighbors+1):\n",
    "    print(f\"LSTMModel {i}\")\n",
    "    train_loader, val_loader, test_loader = createLoaders(pd.DataFrame(df_PeMS.iloc[:, i]), window_size=_window_size, stride=_stride)\n",
    "    models_univaritate_LSTM[f\"LSTMModel {i}\"] = { \n",
    "                                                \"model\": LSTMModel(1, 32, 1),\n",
    "                                                \"train_loader\": train_loader,\n",
    "                                                \"val_loader\": val_loader,\n",
    "                                                \"test_loader\": test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_LSTM = 100\n",
    "\n",
    "for i in range(n_neighbors+1):\n",
    "    train_model(models_univaritate_LSTM[f\"LSTMModel {i}\"][\"model\"], \n",
    "                models_univaritate_LSTM[f\"LSTMModel {i}\"][\"train_loader\"], \n",
    "                models_univaritate_LSTM[f\"LSTMModel {i}\"][\"val_loader\"], \n",
    "                f\"./{normalization}/epoch_{num_epochs_LSTM}/nb_captor_{n_neighbors+1}/univariate_LSTM_model_{i}.pkl\", num_epochs=num_epochs_LSTM, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_univaritate_GRU = {}\n",
    "\n",
    "for i in range(n_neighbors+1):\n",
    "    print(f\"GRUModel {i}\")\n",
    "    train_loader, val_loader, test_loader = createLoaders(pd.DataFrame(df_PeMS.iloc[:, i]), window_size=_window_size, stride=_stride)\n",
    "    models_univaritate_GRU[f\"GRUModel {i}\"] = { \n",
    "                                                \"model\": GRUModel(1, 32, 1),\n",
    "                                                \"train_loader\": train_loader,\n",
    "                                                \"val_loader\": val_loader,\n",
    "                                                \"test_loader\": test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_GRU = 100\n",
    "\n",
    "for i in range(n_neighbors+1):\n",
    "    train_model(models_univaritate_GRU[f\"GRUModel {i}\"][\"model\"], \n",
    "                models_univaritate_GRU[f\"GRUModel {i}\"][\"train_loader\"], \n",
    "                models_univaritate_GRU[f\"GRUModel {i}\"][\"val_loader\"], \n",
    "                f\"./{normalization}/epoch_{num_epochs_GRU}/nb_captor_{n_neighbors+1}/univariate_GRU_model_{i}.pkl\", num_epochs=num_epochs_GRU, remove=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Multivariate vs Univariate (TGCN VS LSTM - GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_prediction(predictions, actuals):\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "    import numpy as np\n",
    "    \n",
    "    indices_by_month = []\n",
    "    EPSILON = 1e-5\n",
    "    # Créer une liste vide pour stocker les données du tableau\n",
    "    data = []\n",
    "    y_pred = predictions[:]\n",
    "    y_true = actuals[:]\n",
    "\n",
    "    signe = \"-\" if np.mean(y_pred - y_true) < 0 else \"+\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)*100\n",
    "    if (mape > 1 or mape < 0):\n",
    "        mape = \"ERROR\"\n",
    "    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))*100\n",
    "    maape =  np.mean(np.arctan(np.abs((y_true - y_pred) / (y_true + EPSILON))))*100\n",
    "    \n",
    "    return [signe, mae, rmse, mape, smape, maape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_col(col, min_val):\n",
    "    if col.name == \"SMAPE\":\n",
    "        color = ['green' if val <= min_val else 'red' for val in col]\n",
    "        return [f'background-color: {c}' for c in color]\n",
    "    else :\n",
    "        return ['' for _ in range(len(col))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_rows(row, min_val):\n",
    "    color = 'green' if row['SMAPE'] == min_val else 'red'\n",
    "    return [f'background-color: {color}'] * len(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_divide_by_max(best_model, test_loader, maximum):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Load the best model and evaluate on the test set\n",
    "    best_model.double()\n",
    "    best_model.eval()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_model.to(device)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = (inputs).to(device)\n",
    "            targets = (targets).squeeze().to(device)\n",
    "            outputs = best_model(inputs).squeeze()\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            # Save the predictions and actual values for plotting later\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            actuals.append(targets.cpu().numpy())\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    # Concatenate the predictions and actuals\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    return (predictions*maximum, actuals*maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Center_reduce\n",
    "######################################################################\n",
    "def test_model_center_reduce(best_model, test_loader, meanstd_dict):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Load the best model and evaluate on the test set\n",
    "    best_model.double()\n",
    "    best_model.eval()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_model.to(device)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = ((inputs*meanstd_dict[\"std\"])+meanstd_dict[\"mean\"]).to(device)\n",
    "            targets = ((targets*meanstd_dict[\"std\"])+meanstd_dict[\"mean\"]).squeeze().to(device)\n",
    "            outputs = best_model(inputs).squeeze()\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            # Save the predictions and actual values for plotting later\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            actuals.append(targets.cpu().numpy())\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    # Concatenate the predictions and actuals\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    return (predictions, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######################################################################\n",
    "# TGCN\n",
    "######################################################################\n",
    "# load best model\n",
    "model_TGCN.load_state_dict(torch.load(f\"./{normalization}/epoch_{num_epochs_TGCN}/nb_captor_{n_neighbors+1}/TGCN_model.pkl\".format(input)))\n",
    "\n",
    "# Make predictions\n",
    "predictions_TGCN, actuals_TGCN = test_model_divide_by_max(model_TGCN, test_loader_TGCN, maximum)\n",
    "\n",
    "\n",
    "for i in range(n_neighbors+1):\n",
    "    \n",
    "    # Save result for each captor\n",
    "    temp = result_prediction(predictions_TGCN[:, i], actuals_TGCN[:, i])\n",
    "    temp.append(f\"TGCN Model captor {i}\")\n",
    "    data = [temp]\n",
    "    \n",
    "######################################################################\n",
    "# LSTM\n",
    "######################################################################\n",
    "    # load best model\n",
    "    models_univaritate_LSTM[f\"LSTMModel {i}\"][\"model\"].load_state_dict(torch.load(f\"./{normalization}/epoch_{num_epochs_LSTM}/nb_captor_{n_neighbors+1}/univariate_LSTM_model_{i}.pkl\".format(input)))\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions_LSTM, actuals_LSTM = test_model_divide_by_max(models_univaritate_LSTM[f\"LSTMModel {i}\"][\"model\"], \n",
    "                                    models_univaritate_LSTM[f\"LSTMModel {i}\"][\"test_loader\"], \n",
    "                                    maximum)\n",
    "    \n",
    "    # Save result\n",
    "    temp = result_prediction(predictions_LSTM, actuals_LSTM)\n",
    "\n",
    "    temp.append(f\"LSTM Model captor {i}\")\n",
    "    data.append(temp)\n",
    "\n",
    "######################################################################\n",
    "# GRU\n",
    "######################################################################\n",
    "    # Load best model\n",
    "    models_univaritate_GRU[f\"GRUModel {i}\"][\"model\"].load_state_dict(torch.load(f\"./{normalization}/epoch_{num_epochs_GRU}/nb_captor_{n_neighbors+1}/univariate_GRU_model_{i}.pkl\".format(input)))\n",
    "    predictions_GRU, actuals_GRU = test_model_divide_by_max(models_univaritate_GRU[f\"GRUModel {i}\"][\"model\"], \n",
    "                                    models_univaritate_GRU[f\"GRUModel {i}\"][\"test_loader\"],\n",
    "                                    maximum)\n",
    "    \n",
    "    # Make predictions\n",
    "    temp = result_prediction(predictions_GRU, actuals_GRU)\n",
    "\n",
    "    # Save results\n",
    "    temp.append(f\"GRU Model captor {i}\")\n",
    "    data.append(temp)\n",
    "\n",
    "######################################################################\n",
    "# Plots\n",
    "######################################################################\n",
    "\n",
    "    plt.figure(figsize=(25, 9))\n",
    "    plt.plot(predictions_TGCN[:, i], color=\"red\", label=\"TGCN pred\")\n",
    "    plt.plot(predictions_LSTM, color=\"black\", label=\"LSTM pred\")\n",
    "    plt.plot(predictions_GRU, color=\"purple\", label=\"GRU pred\" )\n",
    "    plt.plot(actuals_LSTM, color=\"orange\", label=\"LSTM true\")\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "######################################################################\n",
    "# Dataframe\n",
    "######################################################################\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Signe error', 'MAE', 'RMSE', 'MAPE', 'SMAPE', 'MAAPE', \"Captor\"])\n",
    "    \n",
    "    # Définir le mois comme index du DataFrame\n",
    "    df.set_index('Captor', inplace=True)\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.width', None)\n",
    "\n",
    "    min_val = df['SMAPE'].min()\n",
    "    #df = df.style.apply(highlight_col, axis=0, min_val=min_val)\n",
    "    df = df.style.apply(highlight_rows, axis=1, min_val=min_val)\n",
    "    display(df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
